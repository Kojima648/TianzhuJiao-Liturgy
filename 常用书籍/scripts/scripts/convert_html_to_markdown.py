# è„šæœ¬åç§°ï¼šconvert_all_books_to_markdown.py
# åŠŸèƒ½æè¿°ï¼šæ‰¹é‡å¤„ç†æ‰€æœ‰ book_xx çš„ç« èŠ‚ HTMLï¼Œæå– class="text" å†…å®¹å¹¶ä¿å­˜ä¸º Markdown æ–‡ä»¶

import os
import re
from bs4 import BeautifulSoup
from markdownify import markdownify as md

# è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

# æ‰€æœ‰ç« èŠ‚é¡µé¢ç›®å½•
DOWNLOAD_BASE = os.path.abspath(os.path.join(SCRIPT_DIR, "..", "..", "downloaded_pages"))

# è¾“å‡º markdown ç›®å½•
OUTPUT_BASE = os.path.abspath(os.path.join(SCRIPT_DIR, "..", "..", "parsed_md"))
os.makedirs(OUTPUT_BASE, exist_ok=True)

# éåŽ†æ‰€æœ‰ book_xx ç›®å½•
for book_dir in os.listdir(DOWNLOAD_BASE):
    book_path = os.path.join(DOWNLOAD_BASE, book_dir)
    if not os.path.isdir(book_path) or not book_dir.startswith("book_"):
        continue

    print(f"\nðŸ“˜ å¤„ç†ä¹¦ç±ï¼š{book_dir}")

    output_book_path = os.path.join(OUTPUT_BASE, book_dir)
    os.makedirs(output_book_path, exist_ok=True)

    for chapter_id in os.listdir(book_path):
        html_path = os.path.join(book_path, chapter_id, "index.html")
        if not os.path.exists(html_path):
            continue

        try:
            with open(html_path, "r", encoding="utf-8") as f:
                soup = BeautifulSoup(f, "html.parser")

            content_div = soup.select_one("div.text")
            if not content_div:
                print(f"âš ï¸ è·³è¿‡ï¼š{chapter_id} ä¸­æœªæ‰¾åˆ° .text åŒºå—")
                continue

            # è½¬æ¢ HTML â†’ Markdown
            html_content = str(content_div)
            markdown_content = md(html_content, heading_style="ATX")
            markdown_content = re.sub(r'\n{3,}', '\n\n', markdown_content).strip()

            md_path = os.path.join(output_book_path, f"{chapter_id}.md")
            with open(md_path, "w", encoding="utf-8") as f:
                f.write(markdown_content)

            print(f"âœ… {book_dir}/{chapter_id}.md å·²ç”Ÿæˆ")

        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼š{book_dir}/{chapter_id} è§£æžå¤±è´¥ -> {e}")
